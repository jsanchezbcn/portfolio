"""
skills/explain_performance.py — User Story 4: Natural-language trade explanation.

ExplainPerformanceSkill accepts a trade_id, loads entry context from trade_journal
and market_intel, fetches current Greeks from the options cache, and returns a
human-readable P&L/performance explanation generated by an LLM.

IMPORTANT: OptionData objects have: delta, gamma, theta, vega, iv — NO rho attribute.

Environment variables:
  LLM_MODEL        : Model name (default "gpt-4.1")

Requires GitHub Copilot CLI to be installed and authenticated.
"""
from __future__ import annotations

import json
import logging
import os
from typing import Any

from copilot import CopilotClient

logger = logging.getLogger(__name__)


class ExplainPerformanceSkill:
    """Generates a natural-language explanation of trade performance.

    Args:
        db:           Initialised DBManager instance.
        options_cache: An object with ``fetch_and_cache_options_for_underlying()``
                       (e.g. from IBKRClient or TastytradeAdapter).
        llm_model:    Model identifier (default from ``LLM_MODEL`` env var).
    """

    def __init__(
        self,
        *,
        db: Any,
        options_cache: Any,
        llm_model: str | None = None,
    ) -> None:
        self.db = db
        self.options_cache = options_cache
        self._model = llm_model or os.getenv("LLM_MODEL", "gpt-4.1")
        self._copilot: CopilotClient = CopilotClient()

    # ------------------------------------------------------------------ #
    # T042 — _load_context                                                #
    # ------------------------------------------------------------------ #

    async def _load_context(self, trade_id: str) -> dict[str, Any] | None:
        """Load trade_journal + market_intel for *trade_id*.

        Returns a merged context dict or None if the trade is not found.
        """
        journal = await self.db.get_trade_journal_entry(trade_id)
        if journal is None:
            return None

        intel_rows: list[dict[str, Any]] = (
            await self.db.get_market_intel_for_trade(trade_id) or []
        )

        # Parse entry_greeks_json if it's a string (asyncpg may return it as str)
        entry_greeks = journal.get("entry_greeks_json", {})
        if isinstance(entry_greeks, str):
            try:
                entry_greeks = json.loads(entry_greeks)
            except (json.JSONDecodeError, TypeError):
                entry_greeks = {}

        return {
            "trade_id": trade_id,
            "symbol": journal.get("symbol", ""),
            "thesis": journal.get("thesis") or "",
            "entry_at": str(journal.get("entry_at", "")),
            "entry_greeks": entry_greeks,
            "recent_sentiment": [
                {
                    "source": row.get("source"),
                    "score": row.get("sentiment_score"),
                    "summary": row.get("content"),
                }
                for row in intel_rows[:5]
            ],
        }

    # ------------------------------------------------------------------ #
    # T043 — _fetch_current_greeks                                        #
    # ------------------------------------------------------------------ #

    async def _fetch_current_greeks(
        self, symbol: str, **kwargs: Any
    ) -> dict[str, Any]:
        """Fetch current option Greeks for *symbol* from the options cache.

        Returns a dict with keys: delta, gamma, theta, vega, iv.
        NOTE: OptionData has no ``rho`` attribute — never include it.
        """
        try:
            options = await self.options_cache.fetch_and_cache_options_for_underlying(
                symbol, **kwargs
            )
            if not options:
                return {}

            # Take the first option as representative (closest ATM ideally)
            opt = options[0]
            return {
                "delta": getattr(opt, "delta", None),
                "gamma": getattr(opt, "gamma", None),
                "theta": getattr(opt, "theta", None),
                "vega": getattr(opt, "vega", None),
                "iv": getattr(opt, "iv", None),
            }
        except Exception:
            logger.exception("Failed to fetch current Greeks for %s", symbol)
            return {}

    # ------------------------------------------------------------------ #
    # T044 — _build_reflection_prompt                                     #
    # ------------------------------------------------------------------ #

    def _build_reflection_prompt(
        self, context: dict[str, Any], current_greeks: dict[str, Any]
    ) -> str:
        """Construct an LLM prompt comparing entry vs current Greeks.

        Instructs the model to call out Vega/Delta divergence explicitly.
        """
        entry_greeks = context.get("entry_greeks", {})
        thesis = context.get("thesis") or "No thesis recorded."
        symbol = context.get("symbol", "UNKNOWN")
        sentiment_lines = "\n".join(
            f"  - Score: {s.get('score')}, Summary: {s.get('summary')}"
            for s in context.get("recent_sentiment", [])
        ) or "  No recent sentiment data."

        # Format Greeks comparison table
        greek_keys = ["delta", "gamma", "theta", "vega", "iv"]
        greeks_table = "\n".join(
            f"  {k.capitalize():6}: entry={entry_greeks.get(k, 'N/A'):>10}  "
            f"current={current_greeks.get(k, 'N/A'):>10}"
            for k in greek_keys
        )

        prompt = (
            f"You are a quantitative trading analyst reviewing a derivatives position.\n\n"
            f"Symbol: {symbol}\n"
            f"Original thesis: {thesis}\n\n"
            f"Greeks comparison (entry → current):\n{greeks_table}\n\n"
            f"Recent market sentiment:\n{sentiment_lines}\n\n"
            f"Task: Write a concise (3–5 sentences) performance explanation.\n"
            f"- Reference the original thesis.\n"
            f"- Explicitly mention Delta and Vega if they changed materially.\n"
            f"- Relate the Greeks movement to the sentiment if relevant.\n"
            f"- Do NOT invent numbers not present above.\n"
            f"- Return plain prose only, no bullet points or JSON."
        )
        return prompt

    # ------------------------------------------------------------------ #
    # T045 — explain (orchestration) + _call_llm helper                  #
    # ------------------------------------------------------------------ #

    async def _call_llm(self, prompt: str) -> str:
        """Send *prompt* to the LLM via GitHub Copilot SDK and return the response text."""
        await self._copilot.start()
        session = await self._copilot.create_session({"model": self._model})
        response = await session.send_and_wait({"prompt": prompt})
        await self._copilot.stop()
        return ((response.data.content if response and response.data else "") or "").strip()

    async def explain(self, trade_id: str) -> str:
        """Generate a natural-language explanation for *trade_id*.

        Returns:
            A plain-text explanation string, or a user-facing "not found"
            message if the trade_id is unknown.
        """
        # T039 — load context; return friendly message if not found
        context = await self._load_context(trade_id)
        if context is None:
            return f"Trade '{trade_id}' not found in the trade journal."

        symbol = context["symbol"]

        # T043 — fetch current Greeks (OptionData has no rho)
        current_greeks = await self._fetch_current_greeks(symbol)

        # T044 — build prompt
        prompt = self._build_reflection_prompt(context, current_greeks)

        # T045 — call LLM
        try:
            explanation = await self._call_llm(prompt)
        except Exception:
            logger.exception("LLM call failed for trade %s", trade_id)
            explanation = (
                f"Unable to generate explanation for trade '{trade_id}' "
                "at this time (LLM unavailable)."
            )

        return explanation
